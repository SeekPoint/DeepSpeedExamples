DeepSpeed-Chat 打造类ChatGPT全流程 笔记二之监督指令微调

https://zhuanlan.zhihu.com/p/641675229

系列文章
0x0. 前言
0x1.   Supervised finetuning (SFT) 教程翻译
      如何训练模型
      如何对SFT checkpoint进行评测?
      模型和数据
    ☀️来自OPT-1.3B及其SFT变体（使用不同微调数据）的提示示例
    ☀️ 一些参数解释和可训练的最大模型
      其它
0x2. 评测脚本解读
0x3. 训练脚本解读
    0x3.1 头文件相关解析
        create_prompt_dataset解析
        工具函数解析
            print_rank_0
            to_device
            save_hf_format
            set_random_seed
            get_all_reduce_mean
            get_optimizer_grouped_parameters
            save_zero_three_model
            load_hf_tokenizer
            convert_linear_layer_to_lora
            convert_lora_to_linear_layer
            only_optimize_lora_parameters
            create_hf_model
    0x3.2 main.py主体解析
        parse_args解析
        main函数解析
0x4. hybrid_engine的细节 & log
0x5. 总结

系列文章
DeepSpeed-Chat 打造类ChatGPT全流程 笔记一
【DeepSpeed 教程翻译】三，在 DeepSpeed中使用 PyTorch Profiler和Flops Profiler
DeepSpeed结合Megatron-LM训练GPT2模型笔记（上）
【DeepSpeed 教程翻译】二，Megatron-LM GPT2，Zero 和 ZeRO-Offload
【DeepSpeed 教程翻译】开始，安装细节和CIFAR-10 Tutorial

0x0. 前言
在 DeepSpeed-Chat 打造类ChatGPT全流程 笔记一 中跑通了DeepSpeed Chat的训练和推理流程，
DeepSpeed Chat的训练流程包含监督指令微调（SFT），Reward模型微调，基于人类反馈的强化学习（RLHF）三个步骤。
接着上面文章的todo，这篇文章主要是解析一下监督指令微调（SFT）阶段的代码实现。

0x1. Supervised finetuning (SFT) 教程翻译
监督微调（SFT）与在自然语言任务（例如，WikiText-103）上的标准语言模型微调非常相似。
主要的区别来自于数据集资源，SFT将收集高质量的查询-回答对来微调模型以达到人类更倾向的生成结果。

如何训练模型
我们提供了多个脚本用于在单个GPU（例如，单个A6000-48G，V100-32G，A100-40G等），
单节点（例如，8/16x V100-32G，8 A100-40G/80G）和多节点设置（例如，64x A100-80G）上进行训练，
这些可以在 training_scripts 目录中找到。例如，如果你有一个单独的A6000-48G，你可以简单地运行对应的脚本

     training_scripts/single_gpu/run_1.3b.sh

来训练一个OPT-1.3b模型。我们的单节点脚本很容易扩展到多节点系统。

如何对SFT checkpoint进行评测?
一旦你使用上述代码完成训练，你可以简单地执行 bash evaluation_scripts/run_prompt.sh

它会要求用户提供两个模型的路径：
(a) 原始预训练模型（即 --model_name_or_path_baseline facebook/opt-1.3b）
和
(b) 微调后的模型（即 --model_name_or_path_finetune output/check_base）。
"prompt_eval.py" 包含了几个可以根据你的喜好进行更新的提示。

模型和数据
由于GPT3没有开源的checkpoint，我们使用了Meta OPT家族的预训练模型（即facebook/opt-1.3b）。
你也可以使用其他预训练模型（如GPT-Neo，Bloom等）。
至于数据集，我们也使用了来自Huggingface数据集的开源数据集，具体如下：

    Dahoas/rm-static
    Dahoas/full-hh-rlhf
    Dahoas/synthetic-instruct-gptj-pairwise
    yitingxie/rlhf-reward-datasets
    openai/webgpt_comparisons
    stanfordnlp/SHP

感谢DeepSpeed RLHF的数据抽象和融合技术，我们现在可以将多个数据源合并用于训练。
然而，重要的是要注意，不同的数据集可能使用不同的提示词（例如，Dohas/rm-static使用"Human:"表示查询，"Assistant:"表示回答）。
因此，用户必须自行对齐这些提示。在我们的例子中，我们一致使用了Dohas/rm-static的格式。
通过我们的评估，我们发现整合多样化的数据集可以提高模型的质量。请参考下一节以获取不同查询-答案对的示例。

☀️来自OPT-1.3B及其SFT变体（使用不同微调数据）的提示示例

在这里插入图片描述
☀️ 一些参数解释和可训练的最大模型
main.py文件中使用的大多数参数都有清晰的解释，如果你有解码器模型微调的经验，通常很容易理解。
然而，如果你对其中任何一个不清楚，请不要犹豫在GitHub问题上向我们求助。
在这一部分，我们提供了一些具体的参数解释和它们的使用方法。

参数	            解释	            注意事项
--data_path	用于微调模型的数据	    你可以指定多个数据资源来训练模型，例如：Dahoas/rm-static Dahoas/full-hh-rlhf
--data_split	为三步训练切分数据	根据InstructGPT，我们提供了切分数据集的能力，使得每个分区只在一个步骤中使用。    设置为"2,4,4"意味着我们分别使用20%，40%，40%的数据在每个步骤中。如果你只做SFT，或者你发现在不同步骤中使用重叠数据是可以的/有帮助的，你可以将它改为"10,0,0"。
--sft_only_data_path	用于微调模型的单响应数据	对于只在步骤1中使用的单响应数据，你应该将它们作为这个参数的一部分，而不是上面的data_path参数。这个参数中的数据集将不会被切分，而只在步骤1中全面使用。
--gradient_checkpoint	为模型启用梯度检查点（也称为激活检查点）	这可以显著降低训练内存成本
--offload	DeepSpeed特定功能。将模型卸载到CPT/NVME以节省内存	这可以在内存消耗较少的情况下训练更大的模型。但是它会减慢训练的速度。
--zero_stage	DeepSpeed特定功能，适用于多GPU系统	这可以帮助将模型/优化器分布在多个GPU上。请参见https://www.deepspeed.ai/tutorials/zero/
--lora_dim	当它大于0时，将启用LoRA	通常，LoRA需要更大的学习率才能更好地收敛
--lora_module_name	启用LoRA模块的范围。
--only_optimize_lora	冻结所有其他参数，只优化LoRA相关参数
--gradient_checkpoint, --lora_dim, only_optimize_lora	当启用LoRA和梯度检查点时，不能启用只优化LoRA	如果全部启用，将影响梯度流（也就是由PyTorch支持的auto-grad系统后端）

对于用户来说，一个重要的考虑是确定他们可以使用当前系统训练的最大模型大小。
在这里，我们提供了一个估计这个限制的方法。假设你不使用卸载功能，并启用
(i)零阶段3（如果使用多个GPU），
(ii)梯度检查点，以及
(iii)LoRA，那么你可以训练的大致最大模型大小（以十亿参数为单位）可以估计为"总GPU内存（GB）除以3"。
例如，如果你有一台单一的A6000-48G GPU，你可能可以训练最多16十亿参数的模型。
需要注意的是，这只是一个粗略的估计，你应该自己验证。

其它
从InstructGPT的工作中，我们建议为了得到更好的人类偏好的答案，让模型过度拟合（即更长的训练周期）。
通过我们的探索，我们发现这对于较小模型的微调，如OPT-1.3B，特别有帮助。值得注意的是，我们在脚本中提供的超参数并没有经过大量的调整。
因此，我们鼓励用户和实践者自己找到最优的配置。此外，我们的系统可以很容易地扩展到其他语言，如中文和日语。
为了证明这一点，我们在"training_scripts/other_language"目录下包含了两个例子。

0x2. 评测脚本解读
    DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/evaluation_scripts/run_prompt.sh
    这个脚本是对输入的模型进行评测，我们看一下内容：

    # You can provide two models to compare the performance of the baseline and the finetuned model
    export CUDA_VISIBLE_DEVICES=0
    python prompt_eval.py \
        --model_name_or_path_baseline XXX \
        --model_name_or_path_finetune XXX

这表示我们可以调用prompt_eval.py来对baseline模型和finetune模型进行对比评测。
所以评测的实现就是这里的prompt_eval.py，接下来对prompt_eval.py做一个解读。

首先是头文件导入部分，除了一些常规的需要用到的包还从DeepSpeed Chat的utils下面导入了2个函数。