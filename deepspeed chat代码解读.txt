deepspeed chat代码解读

https://zhuanlan.zhihu.com/p/626420999

0
deepspeed_chat主要程序在文件夹\DeepSpeedExamples\applications\DeepSpeed-Chat\中。

在模型从 ”预训练模型->instructGPT模型“的过程中需要以下三个步骤。也分别对应程序中的三个文件夹。

    step1_supervised_finetuning。对预训练模型，即actor模型进行ft。
    step2_reward_model_finetuning。对reward模型进行ft。
    step3_rlhf_finetuning。使用reward模型对actor模型进行rlhf的过程。
可以看出，step1，和step2是高度相似的。

step1所有参数，共24个
数据地址相关：
--data_path 训练数据路径。多个数据集格式为：dataset1-path dataset2-path

--data_split 训练数据分组

--sft_only_data_path 只进行sft阶段的数据

--data_output_path 临时数据的存放地址

模型地址相关:
--model_name_or_path 预训练模型的地址，或者huggingface网站上的模型地址

--output_dir 训练完的模型输出位置

训练中的超参数设置相关：
--per_device_train_batch_size 每一个设备的训练过程批次大小

--per_device_eval_batch_size 每一个设备的评价过程批次大小

--max_seq_len 最大序列长度

--learning_rate 初始学习率

--seed

--weight_decay 权重衰减（网络反向传导进行学习）

--num_train_epochs 训练回合次数

--gradient_accumulation_steps 累计多少步计算之后进行学习更新参数

--num_warmup_steps 热身步数

--lr_scheduler_type 学习率的调整方式，
                    可选“linear", "cosine", "cosine_with_restarts", "polynomial","constant", "constant_with_warmup"

硬件使用相关：
--local_rank决定是否分布式训练

lora优化相关：
--lora_dim 如果>0，使用lora进行高效训练

--lora_module__name 对哪些层使用Lora

--only_optimize_lora 是否只优化lora参数

deepspeed的加速技术相关：
--gradient_checkpointing 启用hf梯度检查点（降低训练过程中的内存消耗）

--disable_dropout 是否启用droppout

--offload 是否启用offload

--zero_stage 对哪个层级使用offload



（以下环节会反复调用这些参数）

step1模型设置阶段
其中main.py是执行这个步骤的主程序。按照代码处理顺序，其所有参数如下。

1是否开启分布式训练。
（参数：local_rank。）

local_rank默认=-1，默认使用本地gpu进行训练。如果不等于-1，则开启分布式训练。

2是否启用offload加速技术。
（参数：offload，zero_stage。）

offload参数决定是否启用ZeRO Offload技术，将数据拷贝进gpu中提升速度。
       offload=True，使用DeepSpeedCPUAdam作为优化器。offload=Flase，使用FusedAdam作为优化器。

zero_stage =0则正常保存。=3则会把模型分开训练，然后保存。

3训练批次。
（参数：per_device_train_batch_size。）

例如，在 4 个 GPU 设备上进行训练，如果每个设备上的训练批次大小为 32，
并且梯度累积步数为 8，那么总的训练批次大小为 32 * 4 * 8 = 1024。
也就是说，需要等到 8 个小批次中的梯度都被计算后，才会进行一次梯度更新。

4保证训练过程可重复性。
（参数：seed。）

5加载分词器->产生参数tokenizer。
（参数：model_name_or_path。）

可以输入本地的模型地址，也可以输入huggingface上模型地址。

6是否启用dropout技术。
（参数：disable_dropout。）

训练时随机忽略一些神经元以减少过拟合风险。

7加载模型->产生参数model。
（参数：model_name_or_path，以及上述所有设置。）

可以输入本地的模型地址，也可以输入huggingface上模型地址。

8判断是否使用lora加速。
（参数：lora_dim，lora_module__name，only_optimize_lora，model）

lora_dim默认=0。 如果>0，使用lora进行高效训练（把整个参数矩阵按数学公式分解成：
                一个竖着的矩阵X一个正方形矩阵X一个横着的矩阵，这样只需要训练其中一个参数矩阵，就可以影响最终结果。）

lora_module__name 决定对哪些层使用Lora。

only_optimize_lora 决定是否只优化lora的参数。

step1数据加载阶段
1数据分组，创建训练数据集，和验证数据集->产生参数train_dataset+ eval_dataset
（参数：local_rank，data_path，data_split，data_output_path，train_phase=1，
  seed，tokenizer，max_seq_len，sft_only_data_path）

data_path：训练数据路径。

data_split：数据分割方式。6，2，2表示把总数居分成三份。step1使用数据占0.6，step2使用数据占0.2，step3使用数据占0.3。

data_output_path：临时数据存放地址。

train_phase=1：=1代表会反向传播更新参数权重。=0代表不会进行反向传播。

seed：保证推理可以重复。

tokenizer：之前加载的分词器。

max_seq_len：文本序列最大长度。

sft_only_data_path：只进行sft阶段的数据。

2数据采样->产生参数train_sampler+ eval_sampler
（参数：train_dataset，eval_dataset）

在数据分组之后，将顺序打乱，为了提高模型的鲁棒性和减少过拟合。

3数据加载器->产生参数train_dataloader+eval_dataloader
（参数：train_sampler， eval_sampler，per_device_eval_batch_size，）

从整个数据集中挑选每个回合所需要的数据量。

step1模型准备阶段
1创建一个优化器->产生参数optimizer
（参数：learning_rate，weight_decay）

创建一个更新参数的优化流程。

优化器将不同的参数分组，其中一般参数会受到权重衰减的影响，偏置参数不会受到权重衰减的影响。

如y=ax+b。a是一般参数。b是偏置参数，是一个常数。

2创建一个学习率调度器->产生参数lr_scheduler
（参数：optimizer，gradient_accumulation_steps累计多少次更新一次，len(train_dataloader)每回合数据长度 ，
       lr_scheduler_type，num_warmup_steps，num_train_epochs）

创建一个动态调整学习率的调度器。

lr_scheduler_type：使用哪种学习率变化策略。

num_warmup_steps：在前多少步期间增大学习率，以便快速进入到微调阶段。

num_training_steps：一共训练多少步。其计算方法如下：

1（每回合）更新权重次数=（每回合）的训练数据长度/累计多少次进行更新一次权重

2 num_training_steps总更新权重次数=（每回合）更新权重次数*总回合数（总回合数由一开始的参数人为指定）

3初始化
将以上一大堆参数整理在一起，初始化一下。

step1训练阶段
1训练
根据损失函数反向传导，更新参数。

2评估
在验证集上计算。

3保存模型
step2=step1
step3
编辑于 2023-05-03 23:52・IP 属地北京